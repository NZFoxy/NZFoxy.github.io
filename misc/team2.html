<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Saolotoga | Ethical Reflections</title>
   	<link rel="stylesheet" href="../styles/minimal-table.css" type="text/css">
</head>

<body>
<!-- Site navigation menu -->
<ul class="navbar">
  <li><a href="../index.html">Home</a>
  <li><a href="ethics.html">Ethical Reflections</a> 
  <li><a href="process.html">Process Support</a>
</ul>

<h1>Ethical Reflections - Theresa Saolotoga - Team Member 2</h1><br>
<p>Team Name: Stream 16 - Group 07</p>

<p><h4>Student Name: Theresa Saolotoga<p>
Student ID: 20109241</p></h4>


<h2>Ethical Issues and Reflections – Theresa Saolotoga</h2>

<h4><em>“While voice assistants are becoming part of our daily lives and major tech giants are competing in acquiring the largest market share, these new technologies are accompanied with new risks for their users, introducing a new attack vector.” (Alepis & Patsakis, 2017) There are many risks and ethical issues behind using voice assistants but mostly as consumers, companies don’t realise that we are not yet familiar with their concepts as well as not reaching the necessary maturity for each device hence the risks that we are considering (Alepis & Patsakis, 2017).<br><br>

Take permissions as an example, it can be straight forward. Applications ask the user for permission to access data and to use other parts of information installed in their device and slowly, many applications start to request more and more permissions (Alepis & Patsakis, 2017). With the increase in permissions, the user’s tolerance is gradually lowered to “requests for sensitive permissions making the users ignore them, without understanding the risks they can be exposed to in the end” (Alepis & Patsakis, 2017). The danger to this is that these permissions can allow control over our devices and expose our private data. These dangerous permissions can eventually access our camera, microphone (record audio), access our location, read messages, read call logs and as well as retrieve our contacts and calendar information. Natural-language user interfaces such as Apple’s Siri, Amazon Alexa, Google Home, Cortana, and Samsung’s Bixby all have access to this information because we allow it to. It’s as simple as saying “Hey Siri, call Mum”, or “Alexa, read my calendar.” These permissions are granted because we need our Voice Assistants to access our data to relay that information to us. But how much is too much?<br><br> 

Amer (Unknown) argues that “Edward Snowden (National Security Agency) leaks are another example where users are concerned about how much of their personal data and browsing is being monitored by the government.” Some would think that researchers are planning to go beyond the usual functionalities of a device by using the “accelerometers and gyroscopes in smartphones to determine a user’s gait” (Amer, Unknown). They would use this information to analyse which apps are opened at what times of day and at which locations (Amer, Unknown). Although it could be used for good reasons, others may use this information to target users by stalking or blackmailing.<br><br> 

Another ethical issue is privacy and surveillance threats. The interface of the Xbox One can be used to spy on its users (Amer, Unknown). The packaging of the Xbox One comes with a camera and a microphone and this is used to help the user to sign into their apps and control the system with voice and gesture. This also helps to launch or accept a Skype call as their Kinect (camera and microphone array) is supposedly always on. Amer (Unknown) argues that “users became concerned that they could be hacked or spied on”, and that their personal information that is stored for the Xbox recognition system which is stored on Microsoft’s cloud servers would be attacked (Orland, 2013). Supposedly that the Kinect is always on, it is always watching our every move, waiting for a command so that it can activate. We as users don’t see what’s damaging to us, will our privacy no longer be ours?
</em></h4><br>

<hr>
<u>References</u><br><br>
• Aeschlimann, Sara, Bleiker, Marco, Wechner, Michael, & Gampe, Anja. (2020). <i>Communicative and social consequences of interactions with voice assistants. </i> Computers in Human Behaviour, Volume 112. <a href="https://www.sciencedirect.com/science/article/pii/S0747563220302181">https://www.sciencedirect.com/science/article/pii/S0747563220302181</a><br><br>

• Alepis, Efthimios and Patsakis, Constantinos. (2017). <i>Monkey Says, Monkey Does: Security and Privacy on Voice Assistants. </i> IEEE Access, vol. 5, pp. 17841-17851, 2017. <a href="https://ieeexplore.ieee.org/abstract/document/8023746">https://ieeexplore.ieee.org/abstract/document/8023746</a><br><br>

• Orland, Kyle. (2013). <i>Hands-on with the Xbox One: Kinect, interface, and OS impressions.</i> Ars Technica. <a href="https://arstechnica.com/gaming/2013/11/hands-on-with-the-xbox-one-kinect-interface-and-os-impressions/">https://arstechnica.com/gaming/2013/11/hands-on-with-the-xbox-one-kinect-interface-and-os-impressions</a><br><br>

<!-- Sign and date the page, it's only polite! -->
<address>Dated: 19 May 2021<br>
  by Theresa Saolotoga.</address><br><br>


		




</html>